# HFT Scanner with Complete CSV Logging

## âœ… Feature Added: Every Scan Logged to CSV

Your UltraFastGrpcScanner now **logs every single scan** to a CSV file, regardless of whether it's tradable or not!

## CSV File Format

**Filename:** `logs/Ultrascanner_YYYY-MM-DD.csv`

Example: `logs/Ultrascanner_2026-01-12.csv`

The file automatically rotates daily - a new file is created at midnight each day.

## CSV Columns

| Column | Description |
|--------|-------------|
| `Sl No.` | Sequential scan number |
| `Timestamp` | ISO 8601 datetime (e.g., 2026-01-12T10:30:45.123Z) |
| `Radiyum Prc` | Current Raydium pool price in USD |
| `Orca prc` | Current Orca pool price in USD |
| `Spread_USD` | Absolute price difference between pools in USD |
| `Spread_PCT` | Price spread as percentage |
| `Net Profit` | Best profit percentage after fees |
| `Trade Possible` | YES if profit > threshold, NO otherwise |
| `Failure Reason` | Reason why trade is not possible (empty if tradable) |

## Example CSV Data

```csv
Sl No.,Timestamp,Radiyum Prc,Orca prc,Spread_USD,Spread_PCT,Net Profit,Trade Possible,Failure Reason
1,2026-01-12T10:30:45.123Z,124.650000,124.523456,0.126544,0.1015,0.1234,NO,Profit 0.1234% below threshold 0.35%
2,2026-01-12T10:30:45.234Z,124.655000,124.530000,0.125000,0.1004,0.1150,NO,Profit 0.1150% below threshold 0.35%
3,2026-01-12T10:30:45.345Z,124.900000,124.540000,0.360000,0.2891,0.4567,YES,
```

## How It Works

### 1. Every Price Update Triggers a Scan
Every time either pool's price updates (via WebSocket), the scanner:
1. Calculates profit for both directions
2. Determines best direction and profit
3. **Logs the scan to CSV immediately**
4. Checks if tradable (profit > 0.35%)
5. If tradable, generates signal.json

### 2. Automatic Daily Rotation
- At midnight (00:00), a new CSV file is automatically created
- Old files are preserved with their date in the filename
- No manual intervention needed

### 3. Complete Data Capture
Every scan is logged, including:
- âœ… Profitable scans (tradable)
- âœ… Unprofitable scans (not tradable)
- âœ… Both arbitrage directions
- âœ… Exact prices and spreads
- âœ… Sequential scan numbers

## Running the HFT Scanner

```bash
npm run hft
```

This starts both:
1. **UltraFastGrpcScanner** - Monitors prices and logs every scan
2. **FastExecutor** - Executes profitable trades

## Console Output

You'll see output like this:

```
[HFT] âš¡âš¡âš¡ ULTRA-FAST HFT SCANNER INITIALIZED âš¡âš¡âš¡
[HFT] Logging every scan to: logs/Ultrascanner_2026-01-12.csv
[HFT] âœ“ Subscribed to SOL/USDC 0.04% Orca (Orca Whirlpool)
[HFT] âœ“ Subscribed to SOL/USDC Raydium (Raydium AMM - 2 vaults)

[SCAN 20] [5.2s] [8.5 updates/s]
  Orca: $124.523456
  Raydium: $124.650000
  Spread: 0.1015%
  Dir 1 (Orcaâ†’Raydium): 0.1234%
  Dir 2 (Raydiumâ†’Orca): -0.0456%
  Best: SOL/USDC 0.04% Orca -> SOL/USDC Raydium (0.1234%)
  Tradable: âŒ NO

[SCAN 40] [10.8s] [9.2 updates/s]
  Orca: $124.540000
  Raydium: $124.900000
  Spread: 0.2891%
  Dir 1 (Orcaâ†’Raydium): 0.4567%
  Dir 2 (Raydiumâ†’Orca): 0.1234%
  Best: SOL/USDC 0.04% Orca -> SOL/USDC Raydium (0.4567%)
  Tradable: âœ… YES

======================================================================
ðŸš¨ PROFITABLE OPPORTUNITY DETECTED!
======================================================================
Best Direction: SOL/USDC 0.04% Orca -> SOL/USDC Raydium
Profit: 0.4567%
Time: 10:30:45 AM
======================================================================
```

## Data Analysis

### Using the CSV for Analysis

You can analyze the logged data with any tool:

**Excel/Google Sheets:**
- Open the CSV file
- Create pivot tables
- Calculate average spreads
- Find profitable patterns

**Python:**
```python
import pandas as pd

# Load data
df = pd.read_csv('logs/Ultrascanner_2026-01-12.csv')

# Analyze profitable opportunities
profitable = df[df['is_tradable'] == 'YES']
print(f"Tradable opportunities: {len(profitable)}")
print(f"Average profit: {profitable['best_profit_pct'].mean():.4f}%")

# Find best times
df['hour'] = pd.to_datetime(df['datetime']).dt.hour
hourly_profits = df.groupby('hour')['best_profit_pct'].mean()
```

**SQL:**
```sql
-- Import CSV to database, then:
SELECT
  DATE(datetime) as date,
  COUNT(*) as total_scans,
  SUM(CASE WHEN is_tradable = 'YES' THEN 1 ELSE 0 END) as profitable_scans,
  AVG(best_profit_pct) as avg_profit_pct,
  MAX(best_profit_pct) as max_profit_pct
FROM ultrascanner_log
GROUP BY date;
```

## File Management

### Log File Location
All CSV files are stored in: `logs/Ultrascanner_YYYY-MM-DD.csv`

### Disk Space
- Each scan is ~200 bytes
- At 10 scans/second = 2 KB/second = 7.2 MB/hour
- Daily file size: ~173 MB (at 10 scans/sec)
- Weekly storage: ~1.2 GB

### Cleanup (Optional)
To automatically clean up old logs after 7 days, add a cron job:

```bash
# Linux/Mac: Add to crontab
0 0 * * * find /path/to/logs -name "Ultrascanner_*.csv" -mtime +7 -delete

# Windows: Add to Task Scheduler
forfiles /p "C:\path\to\logs" /m Ultrascanner_*.csv /d -7 /c "cmd /c del @path"
```

## Key Features

### 1. No Data Loss
- Every scan is logged immediately after calculation
- File is flushed after each write
- Even if the process crashes, all previous scans are saved

### 2. Performance Optimized
- CSV append is fast (~0.1ms per write)
- No impact on scanning speed
- Async I/O doesn't block price updates

### 3. Easy to Parse
- Standard CSV format
- Compatible with all data analysis tools
- Clear column names

### 4. Daily Rotation
- Automatic file creation at midnight
- Organized by date
- Easy to archive or delete old data

## Troubleshooting

### "Permission denied" error
- Check that `logs/` directory exists and is writable
- Run: `mkdir -p logs && chmod 755 logs`

### CSV file not created
- Scanner automatically creates `logs/` directory
- If it fails, manually create: `mkdir logs`

### Large file sizes
- Normal for high-frequency scanning
- Consider implementing compression for old files
- Or reduce scan frequency (not recommended for HFT)

## Summary

âœ… **Every scan is now logged to CSV**
âœ… **Includes tradable AND non-tradable scans**
âœ… **Automatic daily file rotation**
âœ… **Complete arbitrage data capture**
âœ… **Ready for data analysis and backtesting**

Run with `npm run hft` and check `logs/Ultrascanner_YYYY-MM-DD.csv` for your data!
